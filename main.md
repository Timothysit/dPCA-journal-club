---
title: dPCA 
separator: <!--s-->
verticalSeparator: <!--v-->
theme: white
revealOptions:
    transition: 'fade'
---




# demixed Principal Component Analysis

[Kobak et al 2016: Demixed principal component analysis of neural population vector](https://elifesciences.org/articles/10989)


<!--s-->


## Principles of dimensionality reduction


<!--s-->


## demixed PCA





<!--s-->

### Code


<!--s-->

## Other dimensionality reduction methods 

Good reviews papers:

 - [Cunningham and Byron 2014: Dimensionality reduction for large-scale neural recordings](https://www.nature.com/articles/nn.3776)
 


<!--s-->

### PCA 

<!--s-->


### Factor analysis

<!--s-->



### t-SNE

<iframe frameborder="0" width="100%" height="500pt" src="https://distill.pub/2016/misread-tsne/"></iframe>

<!--v-->

<div id='left'>

Pros

 - list 
 - of 
 - pros

</div>

<div id ='right'>

Cons 

 - list 
 - of 
 - cons

</div>

<!--v-->

Some example implementations:

 - [Dimitriadis 2018: t-SNE visualization of large scale neural recordings](https://www.mitpressjournals.org/doi/full/10.1162/neco_a_01097)



<!--s-->


### Gaussian Process Factor Analysis 

<!--s-->

### Independent Component Analysis 

<!--s-->

### Latent Factor Analysis via Dynamical Systems (LFADS)



[Pandarinath 2018: Inferring single-trial neural population dynamics using sequential auto-encoders](https://www.nature.com/articles/s41592-018-0109-9)



<!--s-->


### Tier-list of dimensionality reduction methods










<style>

#left {
	margin: 10px 0 15px 20px;
	text-align: left;
	float: left;
	z-index:-10;
	width:48%;
	font-size: 0.85em;
	line-height: 1.5; 
}

#right {
	margin: 10px 0 15px 0;
	float: right;
	text-align: left;
	z-index:-10;
	width:48%;
	font-size: 0.85em;
	line-height: 1.5; 
}

</style>


